{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clarify Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sm_version = sagemaker.__version__\n",
    "if sm_version[0] ==\"1\":\n",
    "    !pip install sagemaker==2.5.5\n",
    "    import sagemaker\n",
    "    \n",
    "import os\n",
    "import boto3\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# If running locally cut and paste Execution role ARN, otherwise use get_execution_role() method\n",
    "# role = ''\n",
    "# role = sagemaker.get_execution_role()\n",
    "bucket = \"2021-demos\"\n",
    "prefix = \"sagemaker/german-data-xgb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic training/inference parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_endpoint_name = 'sm-clarify-german-xgb'\n",
    "xgb_model_name = 'xgboost-german-model'\n",
    "train_instance_count = 1\n",
    "train_instance_type = 'ml.c5.4xlarge'\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = 'ml.c5.4xlarge'\n",
    "batch_transform_instance_count = 1\n",
    "batch_transform_instance_type = 'ml.c5.4xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Data'):\n",
    "    os.makedirs('Data')\n",
    "    \n",
    "local_data_path = './Data/german.data'\n",
    "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
    "os.system('wget -O %s %s' %(local_data_path, url))\n",
    "\n",
    "data = pd.read_csv(local_data_path, header=None, sep=\" \")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "# Details here: https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_data(german):\n",
    "    german.columns=[\"CheckingAC_Status\", \"MaturityMonths\", \"CreditHistory\", \"Purpose\", \n",
    "                    \"LoanAmount\", \"SavingsAC\", \"Employment\", \"InstallmentPctOfIncome\", \n",
    "                    \"SexAndStatus\", \"OtherDebts\", \"PresentResidenceYears\", \"Property\", \n",
    "                    \"Age\", \"OtherInstallmentPlans\", \"Housing\", \"NumExistingLoans\", \"Job\", \n",
    "                    \"Dependents\", \"Telephone\", \"ForeignWorker\", \"Class1Good2Bad\"]\n",
    "    \n",
    "    df = pd.DataFrame(2-german.Class1Good2Bad) # Conver to good=1, bad=0\n",
    "    res = pd.get_dummies(german.CheckingAC_Status) # A11 A12 A13 A14\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    df = pd.concat([df,german.MaturityMonths], axis=1, sort=False)\n",
    "    res = pd.get_dummies(german.CreditHistory) # A30 A31 A32 A33 A34\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    res = pd.get_dummies(german.Purpose)\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    df = pd.concat([df,german.LoanAmount], axis=1, sort=False)\n",
    "    res = pd.get_dummies(german.SavingsAC)\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    res = pd.get_dummies(german.Employment)\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    df = pd.concat([df,german.InstallmentPctOfIncome], axis=1, sort=False)\n",
    "    res = pd.get_dummies(german.SexAndStatus)\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    res = pd.get_dummies(german.OtherDebts)\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    df = pd.concat([df,german.PresentResidenceYears], axis=1, sort=False)\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    res = pd.get_dummies(german.Property)\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    df = pd.concat([df,german.Age], axis=1, sort=False)\n",
    "    res = pd.get_dummies(german.OtherInstallmentPlans)\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    res = pd.get_dummies(german.Housing)\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    df = pd.concat([df,german.NumExistingLoans], axis=1, sort=False)\n",
    "    res = pd.get_dummies(german.Job)\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    df = pd.concat([df,german.Dependents], axis=1, sort=False)\n",
    "    res = pd.DataFrame({'Telephone': german.Telephone.str.slice(3,4).astype(int)-1})\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    res = pd.DataFrame({'ForeignWorker': abs(german.ForeignWorker.str.slice(3,4).astype(int)-2)})\n",
    "    df = pd.concat([df,res], axis=1, sort=False)\n",
    "    \n",
    "    print(\"DF shape {}\".format(df.shape))\n",
    "    print(\"DF columns: \\n{}\".format(df.columns))\n",
    "    \n",
    "    # Separate X and y in the dataset\n",
    "    X = df.drop(['Class1Good2Bad'], axis=1)\n",
    "    y = df.Class1Good2Bad\n",
    "    print(\"X shape: {}, y shape: {}\".format(X.shape, y.shape))\n",
    "    \n",
    "    return X, y, df\n",
    "\n",
    "X, y, df = _preprocess_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.sample(frac=0.8, random_state=200)\n",
    "other_data = df.drop(train_data.index)\n",
    "validation_data = other_data.sample(frac=0.5, random_state=200)\n",
    "test_data = other_data.drop(validation_data.index)\n",
    "del other_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/tmp/train_data.csv'\n",
    "train_data.to_csv(train_file, index=False, header=False)\n",
    "train_data_s3_path = session.upload_data( bucket=bucket, path=train_file, key_prefix=prefix + \"/train\")\n",
    "print('Training data uploaded to: ' + train_data_s3_path)\n",
    "\n",
    "validation_file = '/tmp/validation_data.csv'\n",
    "validation_data.to_csv(validation_file, index=False, header=False)\n",
    "validation_data_s3_path = session.upload_data( bucket=bucket, path=validation_file, key_prefix=prefix + \"/validation\")\n",
    "print('Validation data uploaded to: ' + validation_data_s3_path)\n",
    "\n",
    "preprocessed_data_file = \"/tmp/X.csv\"\n",
    "preprocessed_label_file = \"/tmp/y.csv\"\n",
    "X.to_csv(preprocessed_data_file, index=None, header=False)\n",
    "y.to_csv(preprocessed_label_file, index=None, header=False)\n",
    "session.upload_data( bucket=bucket,path=preprocessed_data_file, key_prefix=prefix + \"/preprocessed_data\")\n",
    "session.upload_data( bucket=bucket,path=preprocessed_label_file, key_prefix=prefix + \"/preprocessed_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "xgb_image_uri = retrieve('xgboost', session.boto_region_name, version=\"latest\")\n",
    "xgb = sagemaker.estimator.Estimator( xgb_image_uri, role, instance_count=train_instance_count, \n",
    "                                    instance_type=train_instance_type, \n",
    "                                    output_path='s3://{}/{}/{}'.format(bucket, prefix, 'xgb_model'),\n",
    "                                    sagemaker_session=session)\n",
    "xgb.set_hyperparameters(max_depth=7, eta=0.3, objective='binary:logistic', num_round=10)\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train/train_data.csv'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/validation/validation_data.csv'.format(bucket, prefix), content_type='csv')\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "xgb_predictor = xgb.deploy(initial_instance_count=predictor_instance_count,\n",
    "                           instance_type=predictor_instance_type,\n",
    "                           serializer=CSVSerializer(),\n",
    "                           deserializer=CSVDeserializer(),\n",
    "                           model_name=xgb_model_name,\n",
    "                           endpoint_name=xgb_endpoint_name )\n",
    "print(\"\\nModel is successfully deployed at the endpoint {xgb_endpoint_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_dataset = sagemaker.s3.S3Downloader.read_file('s3://{}/{}/{}/X.csv'.format(bucket, prefix, 'preprocessed_data'))\n",
    "probs_list = xgb_predictor.predict(train_dataset)\n",
    "probs = np.array(probs_list[0], dtype=float)\n",
    "\n",
    "pred_labels = (probs >= 0.5).astype(dtype=np.int32)\n",
    "\n",
    "labels_str = sagemaker.s3.S3Downloader.read_file('s3://{}/{}/{}/y.csv'.format(bucket, prefix, 'preprocessed_data'))\n",
    "labels = np.fromstring(labels_str, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(labels, pred_labels):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    import matplotlib.pyplot as plt\n",
    "    fpr, tpr, thrs = roc_curve(labels, pred_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    lw=2\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc )\n",
    "    plt.plot([0,1], [0,1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy score for online predictions\", accuracy_score(pred_labels, labels))\n",
    "plot_roc_curve(labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
